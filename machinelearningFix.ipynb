{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e1989b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Basisstijl voor plots\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "# STAP 1: DATA INLADEN EN EERSTE VERKENNING\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"STAP 1: DATA INLADEN EN EERSTE VERKENNING\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "\n",
    "# Laad de dataset\n",
    "\n",
    "df = pd.read_csv(\"ML-sleep_health_lifestyle_dataset_5000_target82.csv\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nDataset geladen met {df.shape[0]} rijen en {df.shape[1]} kolommen\")\n",
    "\n",
    "print(\"\\nEerste 5 rijen:\")\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9769f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STAP 2: DATA INSPECTIE EN KWALITEITSCONTROLE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAP 2: DATA INSPECTIE EN KWALITEITSCONTROLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nInformatie over datatypes en geheugengebruik:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"CONTROLE OP ONTBREKENDE WAARDEN\")\n",
    "print(\"-\"*80)\n",
    "missing_values = df.isnull().sum()\n",
    "missing_pct = 100 * df.isnull().sum() / len(df)\n",
    "missing_table = pd.DataFrame({\n",
    "    'Aantal Missing': missing_values,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_table[missing_table['Aantal Missing'] > 0])\n",
    "\n",
    "if missing_table['Aantal Missing'].sum() == 0:\n",
    "    print(\"\\n‚úì Geen ontbrekende waarden gevonden in de dataset\")\n",
    "    print(\"Dit is gunstig voor modelontwikkeling omdat we geen imputatiestrategie√´n nodig hebben.\")\n",
    "else:\n",
    "    print(\"\\n‚ö† Er zijn ontbrekende waarden die behandeld moeten worden\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"BESCHRIJVENDE STATISTIEKEN - NUMERIEKE VARIABELEN\")\n",
    "print(\"-\"*80)\n",
    "display(df.describe())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3504e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STAP 3: TARGET VARIABELE ANALYSE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAP 3: TARGET VARIABELE ANALYSE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nDe target variabele 'Sleep Disorder' vormt de basis voor ons classificatieprobleem.\")\n",
    "print(\"We onderzoeken de verdeling van klassen om te bepalen of we te maken hebben met\")\n",
    "print(\"class imbalance en of dit speciale aandacht vereist tijdens modeltraining.\\n\")\n",
    "\n",
    "# Vervang NaN in Sleep Disorder met 'None'\n",
    "df['Sleep Disorder'] = df['Sleep Disorder'].fillna('None')\n",
    "\n",
    "print(\"Verdeling van Sleep Disorder:\")\n",
    "class_distribution = df['Sleep Disorder'].value_counts()\n",
    "print(class_distribution)\n",
    "print(f\"\\nPercentages:\")\n",
    "print(df['Sleep Disorder'].value_counts(normalize=True) * 100)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "df['Sleep Disorder'].value_counts().plot(kind='bar', color=['#2ecc71', '#e74c3c', '#3498db'])\n",
    "plt.title(\"Verdeling van Sleep Disorder Klassen\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Klasse\")\n",
    "plt.ylabel(\"Aantal observaties\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"INTERPRETATIE VAN KLASSENBALANS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Bereken imbalance ratio\n",
    "min_class = class_distribution.min()\n",
    "max_class = class_distribution.max()\n",
    "imbalance_ratio = max_class / min_class\n",
    "\n",
    "print(f\"\\nImbalance ratio (grootste/kleinste klasse): {imbalance_ratio:.2f}\")\n",
    "\n",
    "if imbalance_ratio < 1.5:\n",
    "    print(\" De klassen zijn redelijk gebalanceerd. Standaard modeltraining is geschikt.\")\n",
    "elif imbalance_ratio < 3:\n",
    "    print(\"Er is enige klassenonevenwichtigheid. Overweeg stratified sampling en\")\n",
    "    print(\"  class_weight='balanced' parameter bij sommige modellen.\")\n",
    "else:\n",
    "    print(\"Significante klassenonevenwichtigheid gedetecteerd!\")\n",
    "    print(\"  Overweeg: SMOTE, class weighting, of stratified k-fold cross-validation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STAP 4: MULTICLASS VS BINARY CLASSIFICATIE - ONDERBOUWING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAP 4: MODELTYPE KEUZE - MULTICLASS VS BINARY CLASSIFICATIE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "RATIONALE VOOR MULTICLASS CLASSIFICATIE:\n",
    "-----------------------------------------\n",
    "\n",
    "Onze target variabele heeft drie categorie√´n:\n",
    "1. None (geen slaapstoornis)\n",
    "2. Insomnia (slapeloosheid)\n",
    "3. Sleep Apnea (slaapapneu)\n",
    "\n",
    "WAAROM MULTICLASS IN PLAATS VAN BINARY?\n",
    "========================================\n",
    "\n",
    "1. KLINISCHE RELEVANTIE:\n",
    "   ‚Ä¢ Insomnia en Sleep Apnea hebben verschillende oorzaken, symptomen en behandelingen\n",
    "   ‚Ä¢ Een binair model (wel/geen stoornis) zou deze cruciale distinctie verliezen\n",
    "   ‚Ä¢ Voor medisch personeel is het essentieel om het TYPE stoornis te identificeren\n",
    "\n",
    "2. BEHANDELINGSIMPLICATIES:\n",
    "   ‚Ä¢ Insomnia ‚Üí vaak cognitieve gedragstherapie, slaaphygi√´ne, medicatie\n",
    "   ‚Ä¢ Sleep Apnea ‚Üí CPAP-apparaat, gewichtsreductie, operatieve ingrepen\n",
    "   ‚Ä¢ De aanpak verschilt fundamenteel\n",
    "\n",
    "3. DIAGNOSTISCHE WAARDE:\n",
    "   ‚Ä¢ Verschillende risicoprofielen: Sleep Apnea correleert met BMI en hartslag,\n",
    "     Insomnia vaak met stress en levensstijlfactoren\n",
    "   ‚Ä¢ Een multiclass model kan deze subtiele patronen onderscheiden\n",
    "\n",
    "4. MODELCOMPLEXITEIT VS INFORMATIEBEHOUD:\n",
    "   ‚Ä¢ Trade-off: multiclass is complexer, maar behoudt essenti√´le informatie\n",
    "   ‚Ä¢ In medische context weegt informatieverlies zwaarder dan modelcomplexiteit\n",
    "\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbce46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# STAP 5: FEATURE TYPE IDENTIFICATIE EN CATEGORISATIE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAP 5: FEATURE TYPE IDENTIFICATIE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Numerieke kolommen\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "# Verwijder Person ID uit numerieke features (is geen predictive feature)\n",
    "num_cols = [col for col in num_cols if col != 'Person ID']\n",
    "\n",
    "# Categorische kolommen\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "# Verwijder target uit categorische features\n",
    "cat_feature_cols = [col for col in cat_cols if col != 'Sleep Disorder']\n",
    "\n",
    "print(f\"\\nNumerieke features ({len(num_cols)}):\")\n",
    "for col in num_cols:\n",
    "    print(f\"  ‚Ä¢ {col}\")\n",
    "\n",
    "print(f\"\\nCategorische features ({len(cat_feature_cols)}):\")\n",
    "for col in cat_feature_cols:\n",
    "    unique_values = df[col].nunique()\n",
    "    print(f\"  ‚Ä¢ {col} ({unique_values} unieke waarden)\")\n",
    "    print(f\"    Waarden: {df[col].unique()[:5].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STAP 6: TRAIN-TEST SPLIT - DATA PARTITIONERING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAP 6: TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "DOEL VAN TRAIN-TEST SPLIT:\n",
    "===========================\n",
    "\n",
    "We splitsen de data in twee sets:\n",
    "1. TRAINING SET: Model leert patronen uit deze data\n",
    "2. TEST SET: Model wordt ge√´valueerd op ongeziene data\n",
    "\n",
    "Dit voorkomt OVERFITTING en geeft realistische performantie schatting.\n",
    "\n",
    "KRITIEK: SPLIT VOOR ALLE TRANSFORMATIES!\n",
    "=========================================\n",
    "\n",
    "We splitsen op de ONBEWERKTE data (na feature identificatie).\n",
    "Alle bewerkingen (outlier behandeling, encoding, scaling) gebeuren DAARNA,\n",
    "APART op train en test set.\n",
    "\n",
    "WAAROM?\n",
    "- Voorkomt data leakage (test info lekt niet naar train)\n",
    "- Scaler fit op train, transform op test\n",
    "- Encoder fit op train, transform op test\n",
    "- Outlier grenzen bepaald op train, toegepast op test\n",
    "\n",
    "SPLIT RATIO OVERWEGINGEN:\n",
    "==========================\n",
    "\n",
    "OPTIES:\n",
    "- 90/10: Maximaal trainingsdata, maar kleine test set (minder betrouwbare metrics)\n",
    "- 80/20: Goede balans (ONZE KEUZE)\n",
    "- 70/30: Meer test data, maar minder trainingsdata\n",
    "- 60/40: Bij zeer kleine datasets\n",
    "\n",
    "ONZE KEUZE: 80/20 SPLIT\n",
    "========================\n",
    "\n",
    "Rationale:\n",
    "- Dataset heeft ~374 samples ‚Üí 80% = ~299 train, 20% = ~75 test\n",
    "- 80% training is genoeg voor model learning\n",
    "- 20% test is acceptabel voor betrouwbare evaluatie (hoewel aan de kleine kant)\n",
    "- Breed geaccepteerd in ML literatuur (Hastie et al., 2009)\n",
    "\n",
    "STRATIFIED SAMPLING:\n",
    "====================\n",
    "\n",
    "stratify=y zorgt dat de klassenverhouding gelijk blijft in train √©n test.\n",
    "\n",
    "Voorbeeld: Als originele data 50% None, 30% Insomnia, 20% Sleep Apnea heeft,\n",
    "dan heeft ZOWEL train ALS test deze verhoudingen.\n",
    "\n",
    "WAAROM STRATIFICATION CRUCIAAL IS:\n",
    "- Voorkomt dat √©√©n klasse oververtegenwoordigd is in test set\n",
    "- Zorgt voor representatieve evaluatie\n",
    "- Essentieel bij (lichte) class imbalance\n",
    "\n",
    "RANDOM STATE:\n",
    "=============\n",
    "random_state=42 zorgt voor reproduceerbaarheid.\n",
    "Elke run geeft identieke split ‚Üí belangrijk voor:\n",
    "- Vergelijking tussen modellen\n",
    "- Rapportage van resultaten\n",
    "- Samenwerking in team\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"UITVOEREN VAN SPLIT OP ONBEWERKTE DATA\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Scheiding van features en target VOOR encoding/scaling\n",
    "X = df.drop(['Sleep Disorder', 'Person ID'], axis=1)  # ‚úì originele data\n",
    "y = df['Sleep Disorder']  # nog als string\n",
    "\n",
    "print(f\"\\nOriginele dataset:\")\n",
    "print(f\"  ‚Ä¢ X shape: {X.shape}\")\n",
    "print(f\"  ‚Ä¢ y shape: {y.shape}\")\n",
    "\n",
    "# Split op onbewerkte data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,  # ‚úì onbewerkte features\n",
    "    y,  # ‚úì onbewerkte target (nog strings)\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTRAINING SET:\")\n",
    "print(f\"  ‚Ä¢ X_train shape: {X_train.shape}\")\n",
    "print(f\"  ‚Ä¢ y_train shape: {y_train.shape}\")\n",
    "print(f\"  ‚Ä¢ Percentage: {100 * len(X_train) / len(X):.1f}%\")\n",
    "\n",
    "print(f\"\\nTEST SET:\")\n",
    "print(f\"  ‚Ä¢ X_test shape: {X_test.shape}\")\n",
    "print(f\"  ‚Ä¢ y_test shape: {y_test.shape}\")\n",
    "print(f\"  ‚Ä¢ Percentage: {100 * len(X_test) / len(X):.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"VERIFICATIE VAN STRATIFICATIE\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(\"\\nKlassenverdeling in ORIGINELE data:\")\n",
    "print(y.value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\nKlassenverdeling in TRAINING set:\")\n",
    "print(y_train.value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\nKlassenverdeling in TEST set:\")\n",
    "print(y_test.value_counts(normalize=True).sort_index())\n",
    "\n",
    "# Visualisatie van stratificatie\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "y.value_counts(normalize=True).sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Original Data')\n",
    "axes[0].set_ylabel('Proportion')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylim(0, 0.6)\n",
    "\n",
    "y_train.value_counts(normalize=True).sort_index().plot(kind='bar', ax=axes[1], color='lightgreen')\n",
    "axes[1].set_title('Training Set (80%)')\n",
    "axes[1].set_ylabel('Proportion')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylim(0, 0.6)\n",
    "\n",
    "y_test.value_counts(normalize=True).sort_index().plot(kind='bar', ax=axes[2], color='lightcoral')\n",
    "axes[2].set_title('Test Set (20%)')\n",
    "axes[2].set_ylabel('Proportion')\n",
    "axes[2].set_xlabel('Class')\n",
    "axes[2].set_ylim(0, 0.6)\n",
    "\n",
    "plt.suptitle('Verificatie Stratified Split - Klassenverhouding blijft gelijk', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Stratificatie succesvol: klassenverhouding identiek in train en test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STAP 7: EXPLORATIEVE DATA ANALYSE (EDA)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAP 7: EXPLORATIEVE DATA ANALYSE (EDA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "BELANGRIJK: EDA wordt uitgevoerd op de TRAINING SET\n",
    "====================================================\n",
    "\n",
    "Na de train-test split in stap 6, voeren we alle analyses uit op de training data.\n",
    "De test set blijft 'ongezien' om data leakage te voorkomen.\n",
    "\n",
    "Dit betekent:\n",
    "- Distributies ‚Üí berekend op train\n",
    "- Correlaties ‚Üí berekend op train  \n",
    "- Outlier grenzen ‚Üí bepaald op train (en toegepast op test in stap 8)\n",
    "- Feature statistics ‚Üí berekend op train\n",
    "\"\"\")\n",
    "\n",
    "# Combineer X_train en y_train voor analyse\n",
    "df_train = X_train.copy()\n",
    "df_train['Sleep Disorder'] = y_train.values\n",
    "\n",
    "print(f\"\\nTraining set voor EDA: {df_train.shape[0]} samples √ó {df_train.shape[1]} kolommen\")\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE IMPORTANCE - WAAROM ZIJN DEZE FEATURES BELANGRIJK?\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE - KLINISCHE RATIONALE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "WAAROM ZIJN DEZE FEATURES BELANGRIJK VOOR SLAAPSTOORNIS CLASSIFICATIE?\n",
    "========================================================================\n",
    "\n",
    "1. SLEEP DURATION (Slaapduur) \n",
    "   ‚Ä¢ Primaire indicator van slaapstoornissen\n",
    "   ‚Ä¢ Insomnia: <6 uur per nacht (chronisch slaaptekort)\n",
    "   ‚Ä¢ Sleep Apnea: vaak normale duur, maar gefragmenteerde slaap\n",
    "   ‚Ä¢ Verwachting: Duidelijk verschil tussen klassen\n",
    "\n",
    "2. QUALITY OF SLEEP (Slaapkwaliteit) \n",
    "   ‚Ä¢ Subjectieve maat (self-reported, schaal 1-10)\n",
    "   ‚Ä¢ Capteert ervaren slaapkwaliteit die objectieve metingen kunnen missen\n",
    "   ‚Ä¢ Lage score bij BEIDE insomnia en sleep apnea\n",
    "   ‚Ä¢ Verwachting: Sterkste predictor voor aanwezigheid slaapstoornis\n",
    "\n",
    "3. STRESS LEVEL (Stressniveau) - \n",
    "   ‚Ä¢ Chronische stress ‚Üí verhoogd cortisol ‚Üí verstoord circadiaans ritme\n",
    "   ‚Ä¢ Bidirectionele relatie: stress ‚Üí slechte slaap ‚Üí meer stress\n",
    "   ‚Ä¢ Vooral relevant voor insomnia (hyperarousal)\n",
    "   ‚Ä¢ Verwachting: Hoog bij insomnia, gemiddeld bij sleep apnea\n",
    "\n",
    "4. PHYSICAL ACTIVITY LEVEL (Fysieke Activiteit) - \n",
    "   ‚Ä¢ Regelmatige beweging verbetert slaapkwaliteit (adenosine opbouw)\n",
    "   ‚Ä¢ Te weinig activiteit ‚Üí verstoorde slaap-waak cyclus\n",
    "   ‚Ä¢ Te veel (overtraining) ‚Üí verhoogde cortisol\n",
    "   ‚Ä¢ Verwachting: Lagere waarden geassocieerd met slaapstoornissen\n",
    "\n",
    "5. HEART RATE (Hartslag) -\n",
    "   ‚Ä¢ Verhoogd bij sleep apnea: repetitieve zuurstoftekort episodes ‚Üí sympathische activatie\n",
    "   ‚Ä¢ Normaal tot laag bij insomnia (compensatiemechanisme)\n",
    "   ‚Ä¢ Discriminerende feature: kan sleep apnea onderscheiden van insomnia\n",
    "   ‚Ä¢ Verwachting: Significant hogere HR bij sleep apnea pati√´nten\n",
    "\n",
    "6. DAILY STEPS (Dagelijkse Stappen) -\n",
    "   ‚Ä¢ Proxy voor algemene fysieke activiteit en lifestyle\n",
    "   ‚Ä¢ Correleert met Physical Activity Level (mogelijke multicollineariteit)\n",
    "   ‚Ä¢ Sedentair gedrag geassocieerd met slaapproblemen\n",
    "   ‚Ä¢ Verwachting: Lagere stappen bij beide slaapstoornissen\n",
    "\n",
    "7. BMI (Body Mass Index)\n",
    "   ‚Ä¢ Obesitas (BMI >30) = grootste risicofactor voor obstructieve sleep apnea\n",
    "   ‚Ä¢ Mechanisme: verhoogd weefsel in luchtwegen ‚Üí obstructie\n",
    "   ‚Ä¢ Minder relevant voor insomnia (meer psychologische factoren)\n",
    "   ‚Ä¢ Verwachting: Sterk verhoogd specifiek in sleep apnea groep\n",
    "\n",
    "8. BLOOD PRESSURE (Bloeddruk) - \n",
    "   ‚Ä¢ Hypertensie sterk geassocieerd met sleep apnea\n",
    "   ‚Ä¢ Chronische zuurstoftekort ‚Üí chronische sympathische activatie\n",
    "   ‚Ä¢ Kan ook verhoogd zijn bij chronische stress (insomnia)\n",
    "   ‚Ä¢ Verwachting: Hogere waarden bij sleep apnea, ook mogelijk bij insomnia\n",
    "\n",
    "9. AGE (Leeftijd) -\n",
    "   ‚Ä¢ Prevalentie sleep apnea neemt toe met leeftijd (weefselverlies, verminderde spierspanning)\n",
    "   ‚Ä¢ Insomnia prevalentie meer variabel over levensfasen\n",
    "   ‚Ä¢ Hormonale veranderingen (menopauze) be√Ønvloeden slaap\n",
    "   ‚Ä¢ Verwachting: Sleep apnea groep gemiddeld ouder\n",
    "\n",
    "10. GENDER (Geslacht) -\n",
    "    ‚Ä¢ Mannen: 2-3x hogere kans op sleep apnea (anatomische verschillen)\n",
    "    ‚Ä¢ Vrouwen: hogere prevalentie insomnia (hormonale factoren, stress)\n",
    "    ‚Ä¢ Belangrijke stratificatie variabele\n",
    "    ‚Ä¢ Verwachting: Gender als moderator voor type slaapstoornis\n",
    "\n",
    "11. OCCUPATION (Beroep) - \n",
    "    ‚Ä¢ Shift werk ‚Üí verstoord circadiaans ritme ‚Üí insomnia\n",
    "    ‚Ä¢ Stress-intensive beroepen ‚Üí hogere insomnia prevalentie\n",
    "    ‚Ä¢ Sedentair werk ‚Üí risico op obesitas ‚Üí sleep apnea\n",
    "    ‚Ä¢ Verwachting: Bepaalde beroepen correleren met specifieke stoornissen\n",
    "\n",
    "12. BMI CATEGORY (BMI Categorie) - \n",
    "    ‚Ä¢ Ordinale versie van BMI (Normal/Overweight/Obese)\n",
    "    ‚Ä¢ Mogelijk redundant ‚Üí overweeg feature selection\n",
    "    ‚Ä¢ Overweight/Obese: directe link met sleep apnea\n",
    "    ‚Ä¢ Verwachting: Mogelijk te verwijderen vanwege multicollineariteit met BMI\n",
    "\n",
    "SAMENVATTING TOP PREDICTORS:\n",
    "- Quality of Sleep: algemene indicator voor ALLE slaapstoornissen\n",
    "- BMI: specifiek voor sleep apnea\n",
    "- Heart Rate: discrimineert tussen sleep apnea vs insomnia\n",
    "- Sleep Duration: algemene indicator voor ernst van problematiek\n",
    "- Stress Level: specifiek voor insomnia\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# GEMIDDELDE FEATURE WAARDEN PER SLEEP DISORDER KLASSE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PER-KLASSE ANALYSE - VERSCHILLEN TUSSEN GROEPEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nDeze analyse toont gemiddelde feature waarden per Sleep Disorder klasse.\")\n",
    "print(\"Grote verschillen tussen klassen duiden op discriminerende features.\\n\")\n",
    "\n",
    "for col in num_cols:\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"FEATURE: {col}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Bereken statistics per klasse\n",
    "    class_stats = df_train.groupby('Sleep Disorder')[col].agg([\n",
    "        ('Mean', 'mean'),\n",
    "        ('Std', 'std'),\n",
    "        ('Min', 'min'),\n",
    "        ('Max', 'max'),\n",
    "        ('Count', 'count')\n",
    "    ]).round(2)\n",
    "    \n",
    "    display(class_stats)\n",
    "    \n",
    "    # Interpretatie\n",
    "    means = df_train.groupby('Sleep Disorder')[col].mean()\n",
    "    max_class = means.idxmax()\n",
    "    min_class = means.idxmin()\n",
    "    difference = means.max() - means.min()\n",
    "    \n",
    "    print(f\"\\n INTERPRETATIE:\")\n",
    "    print(f\"  ‚Ä¢ Hoogste gemiddelde: '{max_class}' = {means[max_class]:.2f}\")\n",
    "    print(f\"  ‚Ä¢ Laagste gemiddelde: '{min_class}' = {means[min_class]:.2f}\")\n",
    "    print(f\"  ‚Ä¢ Verschil: {difference:.2f} ({(difference/means.mean())*100:.1f}% van gemiddelde)\")\n",
    "    \n",
    "    # Conclusie\n",
    "    if difference / means.mean() > 0.2:  # >20% verschil\n",
    "        print(f\"  ‚úì STERKE DISCRIMINERENDE FEATURE (>20% verschil)\")\n",
    "    elif difference / means.mean() > 0.1:  # 10-20% verschil\n",
    "        print(f\"  ‚Üí Matige discriminerende feature (10-20% verschil)\")\n",
    "    else:\n",
    "        print(f\"  ‚ö† Zwakke discriminerende feature (<10% verschil)\")\n",
    "\n",
    "# ============================================================================\n",
    "# DISTRIBUTIE VAN NUMERIEKE VARIABELEN\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DISTRIBUTIE VAN NUMERIEKE VARIABELEN (TRAINING SET)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Maak histogrammen van TRAIN data\n",
    "axes = df_train[num_cols].hist(figsize=(15, 12), bins=20, edgecolor='black')\n",
    "plt.suptitle(\"Histogrammen van Numerieke Variabelen (Training Set)\", \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "try:\n",
    "    ax_list = axes.flatten()\n",
    "except Exception:\n",
    "    ax_list = [axes] if hasattr(axes, 'get_axes') else list(axes)\n",
    "    \n",
    "for ax in ax_list:\n",
    "    ax.set_xlabel('Waarde')\n",
    "    ax.set_ylabel('Frequentie')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "INTERPRETATIE VAN DISTRIBUTIES:\n",
    "================================\n",
    "\n",
    "- Sleep Duration: \n",
    "  - Normalish verdeling rond 7-8 uur (verwacht patroon)\n",
    "  - Mogelijk bimodaal (twee pieken: normale slapers vs insomnia)\n",
    "  \n",
    "- Quality of Sleep: \n",
    "  - Concentratie rond hogere waarden (7-9)\n",
    "  - Linker staart: slaapstoornis pati√´nten\n",
    "  \n",
    "- Stress Level: \n",
    "  - Spreiding over gehele schaal (1-10)\n",
    "  - Mogelijk uniform of licht rechts-scheef\n",
    "  \n",
    "- Physical Activity Level: \n",
    "  - Variatie in activiteitsniveaus\n",
    "  - Check of correlatie met Daily Steps (multicollineariteit)\n",
    "  \n",
    "- Heart Rate: \n",
    "  - Concentratie rond 70-80 bpm (normaal rustritme)\n",
    "  - Rechter staart: mogelijk sleep apnea pati√´nten\n",
    "  \n",
    "- Daily Steps: \n",
    "  - Rechtse scheefheid (veel lage waarden, enkele zeer hoge)\n",
    "  - Extreme waarden (>15000) mogelijk tracking fouten of atleten\n",
    "  \n",
    "- BMI:\n",
    "  - Rechts-scheve verdeling (normale populatie + obese groep)\n",
    "  - Verwacht patroon voor algemene populatie\n",
    "  \n",
    "- Age:\n",
    "  - Spreiding over volwassen leeftijden\n",
    "  - Check of ouderen oververtegenwoordigd in sleep apnea groep\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# CORRELATIE ANALYSE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CORRELATIE ANALYSE (TRAINING SET)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nCorrelatiematrix geeft inzicht in lineaire relaties tussen variabelen.\")\n",
    "print(\"Hoge correlaties tussen features kunnen wijzen op multicollineariteit.\\n\")\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df_train[num_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt='.2f', \n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title(\"Correlatie Heatmap - Numerieke Variabelen (Training Set)\", \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identificeer sterke correlaties (|r| > 0.7, exclusief diagonaal)\n",
    "print(\"\\nSterk gecorreleerde variabelen (|r| > 0.7):\")\n",
    "strong_correlations = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "            strong_correlations.append({\n",
    "                'Var1': correlation_matrix.columns[i],\n",
    "                'Var2': correlation_matrix.columns[j],\n",
    "                'Correlation': correlation_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "if strong_correlations:\n",
    "    print(\"\\n‚ö†Ô∏è MULTICOLLINEARITEIT GEDETECTEERD:\")\n",
    "    for corr in strong_correlations:\n",
    "        print(f\"  ‚Ä¢ {corr['Var1']} ‚Üî {corr['Var2']}: r = {corr['Correlation']:.3f}\")\n",
    "    print(\"\\nüí° AANBEVELING: Overweeg √©√©n van deze features te verwijderen in feature selection fase.\")\n",
    "else:\n",
    "    print(\"  ‚úì Geen sterke correlaties gevonden (geen multicollineariteit issues)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PAIRPLOT - RELATIES TUSSEN BELANGRIJKE VARIABELEN\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PAIRPLOT - RELATIES TUSSEN BELANGRIJKE VARIABELEN (TRAINING SET)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Selecteer subset voor pairplot (anders te groot)\n",
    "cols_for_pairplot = [\n",
    "    'Sleep Duration',\n",
    "    'Quality of Sleep',\n",
    "    'Stress Level',\n",
    "    'Physical Activity Level',\n",
    "    'Heart Rate',\n",
    "    'Daily Steps'\n",
    "]\n",
    "cols_for_pairplot = [c for c in cols_for_pairplot if c in df_train.columns]\n",
    "\n",
    "print(f\"\\nPairplot van {len(cols_for_pairplot)} belangrijkste variabelen\")\n",
    "print(\"Dit helpt om non-lineaire relaties en clusters te identificeren.\")\n",
    "print(\"Kleuren tonen verschillende Sleep Disorder klassen.\\n\")\n",
    "\n",
    "sns.pairplot(df_train[cols_for_pairplot + ['Sleep Disorder']], \n",
    "             hue='Sleep Disorder', diag_kind='kde', palette='Set2')\n",
    "plt.suptitle(\"Pairplot - Relaties tussen Features (Training Set)\", \n",
    "             y=1.01, fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "INTERPRETATIE PAIRPLOT:\n",
    "======================\n",
    "\n",
    "LET OP:\n",
    "- Clusters per kleur: duidelijke scheiding tussen klassen = goede feature\n",
    "- Overlap tussen kleuren: moeilijk te onderscheiden klassen\n",
    "- Diagonaal (KDE plots): distributie per klasse\n",
    "- Off-diagonal scatter plots: bivariate relaties\n",
    "\n",
    "VERWACHT:\n",
    "- BMI vs Heart Rate: mogelijk cluster voor sleep apnea (hoog BMI + hoge HR)\n",
    "- Quality of Sleep vs Sleep Duration: positieve correlatie\n",
    "- Stress Level vs Quality of Sleep: negatieve correlatie\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì EDA VOLTOOID OP TRAINING SET\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nBelangrijkste bevindingen worden gebruikt voor:\")\n",
    "print(\"  ‚Ä¢ Outlier behandeling (stap 8)\")\n",
    "print(\"  ‚Ä¢ Feature selection (stap 11)\")\n",
    "print(\"  ‚Ä¢ Model keuze en interpretatie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc56110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STAP 8: OUTLIER DETECTIE EN BEHANDELING - GEFUNDEERDE AANPAK \n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAP 8: OUTLIER DETECTIE EN BEHANDELING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "METHODOLOGIE: IQR (INTERQUARTILE RANGE) METHODE\n",
    "================================================\n",
    "\n",
    "De IQR-methode definieert outliers als waarden die buiten de volgende grenzen vallen:\n",
    "- Lower bound = Q1 - 1.5 √ó IQR\n",
    "- Upper bound = Q3 + 1.5 √ó IQR\n",
    "\n",
    "KRITISCHE VRAAG: MOETEN WE OUTLIERS VERWIJDEREN?\n",
    "==================================================\n",
    "\n",
    "In dit project verwijderen we outliers niet automatisch. In plaats daarvan passen we een conservatieve\n",
    "capping/winsorization toe: zeer hoge of lage waarden worden begrensd tot een minimum of maximum.\n",
    "Op deze manier behouden we alle observaties (belangrijk in medische datasets), maar verminderen\n",
    "we de invloed van onrepresentatieve uitschieters op het model.\n",
    "\n",
    "BELANGRIJK: DATA LEAKAGE PREVENTIE\n",
    "===================================\n",
    "\n",
    "We berekenen outlier grenzen (Q1, Q3, IQR) ALLEEN op TRAINING data.\n",
    "Deze grenzen worden vervolgens toegepast op ZOWEL train ALS test data.\n",
    "\n",
    "Werkwijze:\n",
    "1. Bereken Q1, Q3, IQR op X_train\n",
    "2. Bepaal lower/upper bounds op basis van train statistics\n",
    "3. Pas capping toe op X_train met deze grenzen\n",
    "4. Pas DEZELFDE grenzen toe op X_test (geen herberekening!)\n",
    "\n",
    "Dit voorkomt data leakage: test set informatie be√Ønvloedt niet de train set.\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 8A: OUTLIER DETECTIE OP TRAINING SET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"OUTLIER IDENTIFICATIE PER VARIABELE (TRAINING SET)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Maak kopie√´n om originele data te behouden\n",
    "X_train_clean = X_train.copy()\n",
    "X_test_clean = X_test.copy()\n",
    "\n",
    "# Identificeer numerieke kolommen in X_train\n",
    "num_cols_train = X_train_clean.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumerieke features in training set: {len(num_cols_train)}\")\n",
    "print(f\"Features: {num_cols_train}\\n\")\n",
    "\n",
    "# Bereken outlier statistics op TRAIN data\n",
    "outlier_info = {}\n",
    "outlier_bounds = {}  # Opslaan voor toepassen op test set\n",
    "\n",
    "for col in num_cols_train:\n",
    "    # Bereken op TRAIN\n",
    "    q1 = X_train_clean[col].quantile(0.25)\n",
    "    q3 = X_train_clean[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Identificeer outliers in train\n",
    "    mask = (X_train_clean[col] < lower) | (X_train_clean[col] > upper)\n",
    "    outlier_count = int(mask.sum())\n",
    "    outlier_pct = 100 * outlier_count / len(X_train_clean)\n",
    "    \n",
    "    # Opslaan voor rapportage\n",
    "    outlier_info[col] = {\n",
    "        'count': outlier_count,\n",
    "        'pct': float(outlier_pct),\n",
    "        'lower': float(lower),\n",
    "        'upper': float(upper),\n",
    "        'Q1': float(q1),\n",
    "        'Q3': float(q3),\n",
    "        'IQR': float(iqr)\n",
    "    }\n",
    "    \n",
    "    # Opslaan bounds voor test set\n",
    "    outlier_bounds[col] = {'lower': lower, 'upper': upper}\n",
    "\n",
    "outlier_summary = pd.DataFrame.from_dict(outlier_info, orient='index')\n",
    "outlier_summary = outlier_summary.sort_values('pct', ascending=False)\n",
    "\n",
    "print(\"\\nOutlier Samenvatting Training Set (gesorteerd op percentage):\")\n",
    "display(outlier_summary)\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"VISUALISATIE: BOXPLOTS VOOR OUTLIER DETECTIE (TRAINING SET)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "n_cols_plot = len(num_cols_train)\n",
    "n_rows = (n_cols_plot + 2) // 3  # Bereken aantal rijen nodig\n",
    "n_cols = min(3, n_cols_plot)\n",
    "\n",
    "plt.figure(figsize=(16, 4 * n_rows))\n",
    "for i, col in enumerate(num_cols_train, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    sns.boxplot(x=X_train_clean[col], color='skyblue')\n",
    "    title = f\"{col}\\n({outlier_summary.loc[col, 'count']:.0f} outliers, {outlier_summary.loc[col, 'pct']:.1f}%)\"\n",
    "    plt.title(title, fontsize=10)\n",
    "    plt.xlabel('')\n",
    "plt.suptitle(\"Boxplots - Outlier Detectie (Training Set)\", fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 8B: OUTLIER BEHANDELING - CAPPING/WINSORIZATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OUTLIER BEHANDELING STRATEGIE - GEFUNDEERDE BESLISSINGEN (CAPPING)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "PRINCIPE: CONSERVATIEVE AANPAK\n",
    "=============================\n",
    "\n",
    "- We verwijderen geen rijen puur op basis van IQR-outliers.\n",
    "- We gebruiken winsorization/clipping (capping) voor sterk scheve/dispersed variabelen\n",
    "  en voor duidelijk onrealistische waarden.\n",
    "- Dit behoudt klinisch relevante extreme cases, maar vermindert de invloed van meetfouten\n",
    "  en ongebruikelijke uitschieters op modeltraining.\n",
    "\n",
    "IMPLEMENTATIE:\n",
    "==============\n",
    "1. Bepaal capping strategie per feature op basis van domeinkennis\n",
    "2. Bereken grenzen op TRAIN set\n",
    "3. Pas toe op TRAIN set\n",
    "4. Pas DEZELFDE grenzen toe op TEST set\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"IMPLEMENTATIE VAN BEHANDELING (CAPPING / WINSORIZATION)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Strategie 1: Winsorization voor Daily Steps (1% - 99%)\n",
    "if 'Daily Steps' in X_train_clean.columns:\n",
    "    print(\"\\n1. DAILY STEPS - Winsorization / Capping (1% - 99%)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # TRAIN: bereken percentiles\n",
    "    low_p_train = X_train_clean['Daily Steps'].quantile(0.01)\n",
    "    high_p_train = X_train_clean['Daily Steps'].quantile(0.99)\n",
    "    \n",
    "    # Toon originele ranges\n",
    "    original_min_train = X_train_clean['Daily Steps'].min()\n",
    "    original_max_train = X_train_clean['Daily Steps'].max()\n",
    "    original_min_test = X_test_clean['Daily Steps'].min()\n",
    "    original_max_test = X_test_clean['Daily Steps'].max()\n",
    "    \n",
    "    print(f\"   TRAIN originele range: {original_min_train:.0f} - {original_max_train:.0f} stappen\")\n",
    "    print(f\"   TEST originele range: {original_min_test:.0f} - {original_max_test:.0f} stappen\")\n",
    "    print(f\"   Capping grenzen (van train): {low_p_train:.0f} - {high_p_train:.0f} stappen\")\n",
    "    \n",
    "    # Pas capping toe op TRAIN\n",
    "    X_train_clean['Daily Steps'] = np.clip(X_train_clean['Daily Steps'], low_p_train, high_p_train)\n",
    "    \n",
    "    # Pas DEZELFDE grenzen toe op TEST\n",
    "    X_test_clean['Daily Steps'] = np.clip(X_test_clean['Daily Steps'], low_p_train, high_p_train)\n",
    "    \n",
    "    print(f\"   ‚úì Capping toegepast op train ({len(X_train_clean)} samples)\")\n",
    "    print(f\"   ‚úì DEZELFDE grenzen toegepast op test ({len(X_test_clean)} samples)\")\n",
    "    print(\"   Rationale: Extreme waarden kunnen tracking fouten zijn. Winsorization behoudt data maar beperkt invloed.\")\n",
    "\n",
    "# Strategie 2: Heart Rate - capping naar plausibele range (40 - 120 bpm)\n",
    "if 'Heart Rate' in X_train_clean.columns:\n",
    "    print(\"\\n2. HEART RATE - Capping naar plausibele range (40 - 120 bpm)\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Medische plausibiliteitsgrenzen (domeinkennis)\n",
    "    hr_lower, hr_upper = 40, 120\n",
    "    \n",
    "    # Toon originele ranges\n",
    "    original_hr_min_train = X_train_clean['Heart Rate'].min()\n",
    "    original_hr_max_train = X_train_clean['Heart Rate'].max()\n",
    "    original_hr_min_test = X_test_clean['Heart Rate'].min()\n",
    "    original_hr_max_test = X_test_clean['Heart Rate'].max()\n",
    "    \n",
    "    print(f\"   TRAIN originele hartslag: {original_hr_min_train:.0f} - {original_hr_max_train:.0f} bpm\")\n",
    "    print(f\"   TEST originele hartslag: {original_hr_min_test:.0f} - {original_hr_max_test:.0f} bpm\")\n",
    "    print(f\"   Capping grenzen (medisch plausibel): {hr_lower} - {hr_upper} bpm\")\n",
    "    \n",
    "    # Pas capping toe op TRAIN\n",
    "    X_train_clean['Heart Rate'] = X_train_clean['Heart Rate'].clip(lower=hr_lower, upper=hr_upper)\n",
    "    \n",
    "    # Pas DEZELFDE grenzen toe op TEST\n",
    "    X_test_clean['Heart Rate'] = X_test_clean['Heart Rate'].clip(lower=hr_lower, upper=hr_upper)\n",
    "    \n",
    "    print(f\"   ‚úì Capping toegepast op train ({len(X_train_clean)} samples)\")\n",
    "    print(f\"   ‚úì DEZELFDE grenzen toegepast op test ({len(X_test_clean)} samples)\")\n",
    "    print(\"   Rationale: Clipping behoudt observaties maar vermindert invloed van onrealistische uitschieters.\")\n",
    "\n",
    "# Strategie 3: Plausibiliteitscontroles (geen verwijdering, enkel rapportage)\n",
    "print(\"\\n3. ANDERE VARIABELEN - Plausibiliteitscheck (geen verwijdering)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Sleep Duration (we behouden, want korte/lange slaap kan klinisch relevant zijn)\n",
    "if 'Sleep Duration' in X_train_clean.columns:\n",
    "    invalid_sleep_train = (X_train_clean['Sleep Duration'] < 0) | (X_train_clean['Sleep Duration'] > 24)\n",
    "    invalid_sleep_test = (X_test_clean['Sleep Duration'] < 0) | (X_test_clean['Sleep Duration'] > 24)\n",
    "    \n",
    "    if invalid_sleep_train.sum() > 0 or invalid_sleep_test.sum() > 0:\n",
    "        print(f\"   ‚ö† Sleep Duration: {invalid_sleep_train.sum()} train + {invalid_sleep_test.sum()} test waarden buiten 0-24 uur\")\n",
    "    else:\n",
    "        print(\"   ‚úì Sleep Duration: alle waarden binnen 0-24 uur (train + test)\")\n",
    "\n",
    "# BMI (optioneel)\n",
    "if 'BMI' in X_train_clean.columns:\n",
    "    invalid_bmi_train = (X_train_clean['BMI'] < 10) | (X_train_clean['BMI'] > 70)\n",
    "    invalid_bmi_test = (X_test_clean['BMI'] < 10) | (X_test_clean['BMI'] > 70)\n",
    "    \n",
    "    if invalid_bmi_train.sum() > 0 or invalid_bmi_test.sum() > 0:\n",
    "        print(f\"   ‚ö† BMI: {invalid_bmi_train.sum()} train + {invalid_bmi_test.sum()} test waarden buiten 10-70\")\n",
    "    else:\n",
    "        print(\"   ‚úì BMI waarden binnen plausibel bereik (train + test)\")\n",
    "\n",
    "# Age\n",
    "if 'Age' in X_train_clean.columns:\n",
    "    invalid_age_train = (X_train_clean['Age'] < 18) | (X_train_clean['Age'] > 100)\n",
    "    invalid_age_test = (X_test_clean['Age'] < 18) | (X_test_clean['Age'] > 100)\n",
    "    \n",
    "    if invalid_age_train.sum() > 0 or invalid_age_test.sum() > 0:\n",
    "        print(f\"   ‚ö† Age: {invalid_age_train.sum()} train + {invalid_age_test.sum()} test waarden buiten 18-100 jaar\")\n",
    "    else:\n",
    "        print(\"   ‚úì Age waarden binnen plausibel bereik (train + test)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 8C: RESULTAAT VAN OUTLIER BEHANDELING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"RESULTAAT VAN OUTLIER BEHANDELING (CAPPING / WINSORIZATION)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# We hebben geen rijen verwijderd; we hebben waarden gecapped/winsorized\n",
    "rows_removed = 0\n",
    "pct_removed = 0.0\n",
    "\n",
    "print(f\"\\nTRAINING SET:\")\n",
    "print(f\"  ‚Ä¢ Originele grootte: {X_train.shape[0]} rijen √ó {X_train.shape[1]} kolommen\")\n",
    "print(f\"  ‚Ä¢ Na behandeling: {X_train_clean.shape[0]} rijen √ó {X_train_clean.shape[1]} kolommen\")\n",
    "print(f\"  ‚Ä¢ Verwijderd: {rows_removed} rijen ({pct_removed:.2f}%)\")\n",
    "\n",
    "print(f\"\\nTEST SET:\")\n",
    "print(f\"  ‚Ä¢ Originele grootte: {X_test.shape[0]} rijen √ó {X_test.shape[1]} kolommen\")\n",
    "print(f\"  ‚Ä¢ Na behandeling: {X_test_clean.shape[0]} rijen √ó {X_test_clean.shape[1]} kolommen\")\n",
    "print(f\"  ‚Ä¢ Verwijderd: {rows_removed} rijen ({pct_removed:.2f}%)\")\n",
    "\n",
    "print(\"\\n‚úì Geen rijen verwijderd - we hebben capping toegepast op extreme waarden\")\n",
    "print(\"‚úì Outlier grenzen bepaald op TRAIN en toegepast op BEIDE sets (geen data leakage)\")\n",
    "print(\"‚úì Extreme waarden beperkt via winsorization/clipping\")\n",
    "\n",
    "# Update de variabelen voor gebruik in volgende stappen\n",
    "X_train = X_train_clean\n",
    "X_test = X_test_clean\n",
    "\n",
    "print(\"\\n X_train en X_test zijn nu updated met outlier behandeling\")\n",
    "print(\"   Deze worden gebruikt in volgende stappen (encoding, scaling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf95802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STAP 9: FEATURE ENCODING - CATEGORISCHE VARIABELEN TRANSFORMEREN\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAP 9: FEATURE ENCODING - CATEGORISCHE VARIABELEN\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "WAAROM ENCODING NODIG IS:\n",
    "=========================\n",
    "Machine learning modellen werken met numerieke waarden. Categorische variabelen\n",
    "zoals 'Gender' (Male/Female) of 'BMI Category' (Normal/Overweight/Obese) moeten\n",
    "worden omgezet naar een numerieke representatie.\n",
    "\n",
    "ENCODING METHODEN:\n",
    "==================\n",
    "1. LABEL ENCODING:\n",
    "   ‚Ä¢ Ordinal categorie√´n: 'Low' ‚Üí 0, 'Medium' ‚Üí 1, 'High' ‚Üí 2\n",
    "   ‚Ä¢ Nadeel: impliceert orde/rangorde (2 > 1 > 0)\n",
    "   ‚Ä¢ Gebruik alleen voor ordinale variabelen of target variabele\n",
    "\n",
    "2. ONE-HOT ENCODING:\n",
    "   ‚Ä¢ Nominale categorie√´n: 'Male' ‚Üí [1,0], 'Female' ‚Üí [0,1]\n",
    "   ‚Ä¢ Voordeel: geen kunstmatige ordinale relatie\n",
    "   ‚Ä¢ Nadeel: verhoogt dimensionaliteit (curse of dimensionality bij veel categorie√´n)\n",
    "   ‚Ä¢ Drop_first=True om multicollineariteit te voorkomen (dummy variable trap)\n",
    "\n",
    "3. NUMERIEKE SPLITS:\n",
    "   ‚Ä¢ Blood Pressure: \"120/80\" ‚Üí Systolic=120, Diastolic=80\n",
    "   ‚Ä¢ Voorkomt explosie van dummy variabelen\n",
    "   ‚Ä¢ Behoudt numerieke relatie\n",
    "\n",
    "ONZE AANPAK MET TRAIN-TEST SPLIT:\n",
    "==================================\n",
    "CRITICAL: Data Leakage Preventie\n",
    "---------------------------------\n",
    "- One-hot encoding: fit op TRAIN, transform op TEST\n",
    "- Label encoding (target): fit op TRAIN, transform op TEST\n",
    "- Encoder leert categorie√´n alleen van train data\n",
    "\n",
    "Waarom?\n",
    "- Test set kan nieuwe categorie√´n hebben die train niet heeft gezien\n",
    "- Encoder moet consistent zijn tussen train en test\n",
    "- Voorkomt dat test informatie lekt naar train\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 9A: BLOOD PRESSURE SPLITS IN SYSTOLIC EN DIASTOLIC\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"BLOOD PRESSURE TRANSFORMATIE\")\n",
    "print(\"-\"*80)\n",
    "print(\"\"\"\n",
    "PROBLEEM: Blood Pressure is categorisch met ~100+ unieke waarden\n",
    "-----------------------------------------------------------------\n",
    "Elke waarde zoals \"120/80\", \"130/85\", etc. zou een aparte dummy kolom krijgen.\n",
    "Dit resulteert in 100+ features ‚Üí curse of dimensionality!\n",
    "\n",
    "OPLOSSING: Split in 2 numerieke features\n",
    "-----------------------------------------\n",
    "\"120/80\" ‚Üí Systolic = 120, Diastolic = 80\n",
    "\n",
    "Voordelen:\n",
    "‚úì Reduceert 100+ dummies naar 2 numerieke features\n",
    "‚úì Behoudt medische betekenis (systolische/diastolische druk)\n",
    "‚úì Modellen kunnen numerieke relaties leren\n",
    "\"\"\")\n",
    "\n",
    "def split_blood_pressure(df):\n",
    "    \"\"\"Split Blood Pressure kolom in Systolic en Diastolic\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Split \"120/80\" in twee delen\n",
    "    bp_split = df['Blood Pressure'].str.split('/', expand=True)\n",
    "    \n",
    "    # Converteer naar integers\n",
    "    df['Systolic'] = bp_split[0].astype(int)\n",
    "    df['Diastolic'] = bp_split[1].astype(int)\n",
    "    \n",
    "    # Verwijder originele Blood Pressure kolom\n",
    "    df = df.drop('Blood Pressure', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(f\"\\nVOOR transformatie:\")\n",
    "print(f\"  ‚Ä¢ X_train shape: {X_train.shape}\")\n",
    "print(f\"  ‚Ä¢ X_test shape: {X_test.shape}\")\n",
    "print(f\"  ‚Ä¢ Blood Pressure unieke waarden in train: {X_train['Blood Pressure'].nunique()}\")\n",
    "print(f\"  ‚Ä¢ Blood Pressure unieke waarden in test: {X_test['Blood Pressure'].nunique()}\")\n",
    "\n",
    "print(\"\\nVoorbeeld Blood Pressure waarden:\")\n",
    "print(X_train['Blood Pressure'].head(10).tolist())\n",
    "\n",
    "# Voer transformatie uit\n",
    "X_train = split_blood_pressure(X_train)\n",
    "X_test = split_blood_pressure(X_test)\n",
    "\n",
    "print(f\"\\nNA transformatie:\")\n",
    "print(f\"  ‚Ä¢ X_train shape: {X_train.shape}\")\n",
    "print(f\"  ‚Ä¢ X_test shape: {X_test.shape}\")\n",
    "\n",
    "print(\"\\nNieuwe kolommen toegevoegd:\")\n",
    "print(f\"  ‚Ä¢ Systolic - Range train: [{X_train['Systolic'].min()}, {X_train['Systolic'].max()}]\")\n",
    "print(f\"  ‚Ä¢ Systolic - Range test: [{X_test['Systolic'].min()}, {X_test['Systolic'].max()}]\")\n",
    "print(f\"  ‚Ä¢ Diastolic - Range train: [{X_train['Diastolic'].min()}, {X_train['Diastolic'].max()}]\")\n",
    "print(f\"  ‚Ä¢ Diastolic - Range test: [{X_test['Diastolic'].min()}, {X_test['Diastolic'].max()}]\")\n",
    "\n",
    "print(\"\\nVoorbeeld eerste 5 rijen:\")\n",
    "print(X_train[['Systolic', 'Diastolic']].head())\n",
    "\n",
    "print(\"\\n‚úì Blood Pressure succesvol gesplitst in 2 numerieke features\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 9B: IDENTIFICEER RESTERENDE CATEGORISCHE FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"IDENTIFICATIE VAN CATEGORISCHE FEATURES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Identificeer categorische kolommen in X_train\n",
    "cat_cols_train = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorische features in training set ({len(cat_cols_train)}):\")\n",
    "for col in cat_cols_train:\n",
    "    unique_vals_train = X_train[col].nunique()\n",
    "    unique_vals_test = X_test[col].nunique()\n",
    "    print(f\"  ‚Ä¢ {col}:\")\n",
    "    print(f\"    - Train: {unique_vals_train} categorie√´n ‚Üí {X_train[col].unique().tolist()}\")\n",
    "    print(f\"    - Test: {unique_vals_test} categorie√´n ‚Üí {X_test[col].unique().tolist()}\")\n",
    "\n",
    "# Check voor nieuwe categorie√´n in test set (kunnen problemen geven)\n",
    "print(\"\\n‚ö†Ô∏è CONTROLE: Nieuwe categorie√´n in test set?\")\n",
    "for col in cat_cols_train:\n",
    "    train_cats = set(X_train[col].unique())\n",
    "    test_cats = set(X_test[col].unique())\n",
    "    new_cats = test_cats - train_cats\n",
    "    \n",
    "    if new_cats:\n",
    "        print(f\"  ‚ö†Ô∏è {col}: Test heeft nieuwe categorie√´n: {new_cats}\")\n",
    "        print(f\"     ‚Üí Deze worden behandeld als 'unknown' tijdens encoding\")\n",
    "    else:\n",
    "        print(f\"  ‚úì {col}: Geen nieuwe categorie√´n in test\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 9C: ONE-HOT ENCODING VOOR FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ONE-HOT ENCODING VOOR FEATURES\")\n",
    "print(\"-\"*80)\n",
    "print(\"\"\"\n",
    "METHODE: pd.get_dummies() met align\n",
    "====================================\n",
    "We gebruiken pandas get_dummies() omdat het eenvoudig is, maar we moeten\n",
    "zorgen dat train en test dezelfde kolommen hebben na encoding.\n",
    "\n",
    "Proces:\n",
    "1. Encode train set ‚Üí krijg dummy kolommen\n",
    "2. Encode test set ‚Üí krijg dummy kolommen\n",
    "3. Align beide sets zodat ze identieke kolommen hebben\n",
    "4. Missende kolommen in test worden gevuld met 0\n",
    "\n",
    "Alternatief: sklearn OneHotEncoder met handle_unknown='ignore'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nVOOR encoding:\")\n",
    "print(f\"  ‚Ä¢ X_train: {X_train.shape[0]} rijen √ó {X_train.shape[1]} kolommen\")\n",
    "print(f\"  ‚Ä¢ X_test: {X_test.shape[0]} rijen √ó {X_test.shape[1]} kolommen\")\n",
    "\n",
    "# One-hot encoding op TRAIN\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=cat_cols_train, drop_first=True)\n",
    "\n",
    "# One-hot encoding op TEST (met dezelfde kolommen)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=cat_cols_train, drop_first=True)\n",
    "\n",
    "print(f\"\\nNA encoding (voor align):\")\n",
    "print(f\"  ‚Ä¢ X_train_encoded: {X_train_encoded.shape[0]} rijen √ó {X_train_encoded.shape[1]} kolommen\")\n",
    "print(f\"  ‚Ä¢ X_test_encoded: {X_test_encoded.shape[0]} rijen √ó {X_test_encoded.shape[1]} kolommen\")\n",
    "\n",
    "# BELANGRIJK: Align zodat beide sets dezelfde kolommen hebben\n",
    "# Kolommen die in train maar niet in test zitten ‚Üí voeg toe aan test met 0\n",
    "# Kolommen die in test maar niet in train zitten ‚Üí verwijder uit test\n",
    "X_train_encoded, X_test_encoded = X_train_encoded.align(X_test_encoded, join='left', axis=1, fill_value=0)\n",
    "\n",
    "print(f\"\\nNA align (train en test hebben nu IDENTIEKE kolommen):\")\n",
    "print(f\"  ‚Ä¢ X_train_encoded: {X_train_encoded.shape[0]} rijen √ó {X_train_encoded.shape[1]} kolommen\")\n",
    "print(f\"  ‚Ä¢ X_test_encoded: {X_test_encoded.shape[0]} rijen √ó {X_test_encoded.shape[1]} kolommen\")\n",
    "\n",
    "# Toon nieuwe kolommen\n",
    "new_cols = [col for col in X_train_encoded.columns if col not in X_train.columns]\n",
    "print(f\"\\nNieuwe dummy kolommen gecre√´erd ({len(new_cols)}):\")\n",
    "for col in new_cols[:15]:  # Toon eerste 15\n",
    "    print(f\"  ‚Ä¢ {col}\")\n",
    "if len(new_cols) > 15:\n",
    "    print(f\"  ... en {len(new_cols) - 15} meer\")\n",
    "\n",
    "print(\"\\n‚úì One-hot encoding voltooid\")\n",
    "print(\"‚úì Train en test hebben identieke kolommen\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 9D: LABEL ENCODING VOOR TARGET VARIABELE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"LABEL ENCODING VOOR TARGET VARIABELE\")\n",
    "print(\"-\"*80)\n",
    "print(\"\"\"\n",
    "Target encoding met sklearn LabelEncoder\n",
    "=========================================\n",
    "Process:\n",
    "1. Fit encoder op y_train (leert de klassen)\n",
    "2. Transform y_train ‚Üí numerieke labels\n",
    "3. Transform y_test met DEZELFDE encoder ‚Üí numerieke labels\n",
    "\n",
    "Dit garandeert consistente encoding tussen train en test.\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nVOOR encoding:\")\n",
    "print(f\"  ‚Ä¢ y_train: {y_train.shape[0]} samples, type: {y_train.dtype}\")\n",
    "print(f\"  ‚Ä¢ y_test: {y_test.shape[0]} samples, type: {y_test.dtype}\")\n",
    "print(f\"\\nUnieke klassen in y_train: {sorted(y_train.unique())}\")\n",
    "print(f\"Unieke klassen in y_test: {sorted(y_test.unique())}\")\n",
    "\n",
    "# Label encoding voor target\n",
    "le = LabelEncoder()\n",
    "\n",
    "# FIT op y_train (encoder leert de klassen van train data)\n",
    "le.fit(y_train)\n",
    "\n",
    "# TRANSFORM beide sets met gefitte encoder\n",
    "y_train_encoded = le.transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# Converteer naar pandas Series voor consistentie\n",
    "y_train_encoded = pd.Series(y_train_encoded, index=y_train.index, name='Sleep Disorder')\n",
    "y_test_encoded = pd.Series(y_test_encoded, index=y_test.index, name='Sleep Disorder')\n",
    "\n",
    "print(f\"\\nNA encoding:\")\n",
    "print(f\"  ‚Ä¢ y_train_encoded: {y_train_encoded.shape[0]} samples, type: {y_train_encoded.dtype}\")\n",
    "print(f\"  ‚Ä¢ y_test_encoded: {y_test_encoded.shape[0]} samples, type: {y_test_encoded.dtype}\")\n",
    "\n",
    "# Toon mapping\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"\\nLabel Encoding Mapping:\")\n",
    "for original, encoded in sorted(label_mapping.items(), key=lambda x: x[1]):\n",
    "    count_train = (y_train_encoded == encoded).sum()\n",
    "    count_test = (y_test_encoded == encoded).sum()\n",
    "    print(f\"  '{original}' ‚Üí {encoded}\")\n",
    "    print(f\"    - Train: {count_train} samples ({100*count_train/len(y_train_encoded):.1f}%)\")\n",
    "    print(f\"    - Test: {count_test} samples ({100*count_test/len(y_test_encoded):.1f}%)\")\n",
    "\n",
    "print(\"\\nRationale: Label encoding voor target is noodzakelijk voor sklearn classificatie.\")\n",
    "print(\"De numerieke waarden hebben geen ordinale betekenis in multiclass setting.\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 9E: VERIFICATIE EN SAMENVATTING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"VERIFICATIE EN SAMENVATTING\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(\"\\nEerste 5 rijen TRAINING set (features + target):\")\n",
    "display(pd.concat([X_train_encoded.head(), y_train_encoded.head()], axis=1))\n",
    "\n",
    "print(\"\\nEerste 5 rijen TEST set (features + target):\")\n",
    "display(pd.concat([X_test_encoded.head(), y_test_encoded.head()], axis=1))\n",
    "\n",
    "print(\"\\nKolomtypes in X_train_encoded:\")\n",
    "print(X_train_encoded.dtypes.value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì FEATURE ENCODING VOLTOOID\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nSamenvatting:\")\n",
    "print(f\"  ‚Ä¢ Blood Pressure: Gesplitst in Systolic + Diastolic (2 numerieke features)\")\n",
    "print(f\"  ‚Ä¢ Categorische features: {len(cat_cols_train)} ‚Üí One-hot encoded\")\n",
    "print(f\"  ‚Ä¢ Train features: {X_train.shape[1]} ‚Üí {X_train_encoded.shape[1]} kolommen\")\n",
    "print(f\"  ‚Ä¢ Test features: {X_test.shape[1]} ‚Üí {X_test_encoded.shape[1]} kolommen\")\n",
    "print(f\"  ‚Ä¢ Target variabele: Label encoded (3 klassen)\")\n",
    "print(f\"  ‚Ä¢ Train samples: {X_train_encoded.shape[0]}\")\n",
    "print(f\"  ‚Ä¢ Test samples: {X_test_encoded.shape[0]}\")\n",
    "\n",
    "print(\"\\n BELANGRIJK: Encoder fit op TRAIN, transform op TEST\")\n",
    "print(\"   Dit voorkomt data leakage!\")\n",
    "\n",
    "print(\"\\nReductie in features:\")\n",
    "print(f\"  ‚Ä¢ Blood Pressure zou ~{X_train['Blood Pressure'].nunique() if 'Blood Pressure' in X_train.columns else 100} dummies geven\")\n",
    "print(f\"  ‚Ä¢ Door splitsing: slechts 2 numerieke features (Systolic, Diastolic)\")\n",
    "print(f\"  ‚Ä¢ Besparing: ~{100-2} features!\")\n",
    "\n",
    "# Update variabelen voor volgende stappen\n",
    "X_train = X_train_encoded\n",
    "X_test = X_test_encoded\n",
    "y_train = y_train_encoded\n",
    "y_test = y_test_encoded\n",
    "\n",
    "print(\"\\n‚úì X_train, X_test, y_train, y_test zijn nu ge-encoded\")\n",
    "print(\"   Deze worden gebruikt in volgende stappen (scaling, modeling)\")\n",
    "\n",
    "# Check correlatie tussen Systolic en Diastolic\n",
    "if 'Systolic' in X_train.columns and 'Diastolic' in X_train.columns:\n",
    "    corr = X_train[['Systolic', 'Diastolic']].corr().iloc[0, 1]\n",
    "    print(f\"\\nüìä CORRELATIE CHECK:\")\n",
    "    print(f\"   Systolic ‚Üî Diastolic: r = {corr:.3f}\")\n",
    "    if abs(corr) > 0.9:\n",
    "        print(f\"   ‚ö†Ô∏è Hoge correlatie gedetecteerd (|r| > 0.9)\")\n",
    "        print(f\"   ‚Üí Overweeg √©√©n van beide te verwijderen om multicollineariteit te reduceren\")\n",
    "    else:\n",
    "        print(f\"   ‚úì Correlatie acceptabel\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"READY VOOR STAP 10: FEATURE SCALING\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c37583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STAP 10: FEATURE SCALING - NORMALISATIE EN STANDAARDISATIE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAP 10: FEATURE SCALING (STANDARDISATIE)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "WAAROM FEATURE SCALING NODIG IS:\n",
    "=================================\n",
    "\n",
    "Variabelen hebben verschillende schalen:\n",
    "- Daily Steps: 0 - 10,000+ \n",
    "- Quality of Sleep: 1 - 10\n",
    "- Heart Rate: 50 - 100 bpm\n",
    "\n",
    "PROBLEEM ZONDER SCALING:\n",
    "========================\n",
    "- Distance-based modellen (KNN) worden gedomineerd door features met grote schaal\n",
    "- Gradient descent convergeert langzamer\n",
    "- Regularisatie (L1/L2) werkt niet eerlijk tussen features\n",
    "\n",
    "METHODEN:\n",
    "=========\n",
    "\n",
    "1. MIN-MAX NORMALISATIE (0-1 range):\n",
    "   x_scaled = (x - x_min) / (x_max - x_min)\n",
    "   ‚Ä¢ Voordeel: Behoudt distributie shape\n",
    "   ‚Ä¢ Nadeel: Gevoelig voor outliers\n",
    "\n",
    "2. STANDARDISATIE (Z-SCORE):\n",
    "   x_scaled = (x - Œº) / œÉ\n",
    "   ‚Ä¢ Voordeel: Robuust tegen outliers, mean=0 en std=1\n",
    "   ‚Ä¢ Nadeel: Geen vaste min/max\n",
    "   ‚Ä¢ BEST PRACTICE voor de meeste ML algoritmen\n",
    "\n",
    "ONZE KEUZE: StandardScaler (Z-score normalisatie)\n",
    "===================================================\n",
    "- Geschikt voor variabelen met outliers (hebben we behandeld in stap 8)\n",
    "- Werkt goed met tree-based modellen √©n lineaire modellen\n",
    "- Industrie standaard in sklearn pipelines\n",
    "\n",
    "CRITICAL: DATA LEAKAGE PREVENTIE\n",
    "=================================\n",
    "- Scaler fit op TRAIN data (leert mean en std van train)\n",
    "- Scaler transform op TRAIN data (past train statistics toe)\n",
    "- Scaler transform op TEST data (past TRAIN statistics toe op test!)\n",
    "- Test set blijft \"ongezien\" - we leren NIETS van test data\n",
    "\n",
    "Waarom?\n",
    "- Als we mean/std berekenen op hele dataset, dan lekt test info naar train\n",
    "- Model performance zou te optimistisch zijn\n",
    "- In productie hebben we ook geen toegang tot test statistics\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"HUIDIGE DATA STATUS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\nTRAINING SET:\")\n",
    "print(f\"  ‚Ä¢ X_train shape: {X_train.shape[0]} samples √ó {X_train.shape[1]} features\")\n",
    "print(f\"  ‚Ä¢ y_train shape: {y_train.shape[0]} samples\")\n",
    "\n",
    "print(f\"\\nTEST SET:\")\n",
    "print(f\"  ‚Ä¢ X_test shape: {X_test.shape[0]} samples √ó {X_test.shape[1]} features\")\n",
    "print(f\"  ‚Ä¢ y_test shape: {y_test.shape[0]} samples\")\n",
    "\n",
    "print(f\"\\nFeature kolommen ({len(X_train.columns)}):\")\n",
    "# Toon eerste 15 kolommen\n",
    "cols_to_show = X_train.columns.tolist()[:15]\n",
    "for col in cols_to_show:\n",
    "    print(f\"  ‚Ä¢ {col}\")\n",
    "if len(X_train.columns) > 15:\n",
    "    print(f\"  ... en {len(X_train.columns) - 15} meer kolommen\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 10A: SCALING OP TRAINING SET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"STAP 10A: STANDARDISATIE OP TRAINING SET\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Toon voorbeeld van niet-geschaalde data (TRAIN)\n",
    "print(\"\\nVoorbeeld TRAIN features VOOR scaling:\")\n",
    "display(X_train.head())\n",
    "\n",
    "print(\"\\nDescriptive statistics TRAIN VOOR scaling:\")\n",
    "display(X_train.describe())\n",
    "\n",
    "# Initialiseer scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# FIT scaler op TRAIN data (leert mean en std van train)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "print(\"\\n Scaler Statistics (geleerd van TRAIN data):\")\n",
    "print(f\"  ‚Ä¢ Mean per feature (eerste 5): {scaler.mean_[:5]}\")\n",
    "print(f\"  ‚Ä¢ Std per feature (eerste 5): {scaler.scale_[:5]}\")\n",
    "\n",
    "# TRANSFORM train data met gefitte scaler\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "# Converteer terug naar DataFrame voor visualisatie\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "print(\"\\nVoorbeeld TRAIN features NA scaling:\")\n",
    "display(X_train_scaled.head())\n",
    "\n",
    "print(\"\\nDescriptive statistics TRAIN NA scaling:\")\n",
    "display(X_train_scaled.describe())\n",
    "\n",
    "print(\"\"\"\n",
    "INTERPRETATIE TRAIN:\n",
    "====================\n",
    "- Mean ‚âà 0 (kleine floating point errors acceptabel)\n",
    "- Std ‚âà 1 voor alle features\n",
    "- Dit is verwacht omdat we scaler gefitted hebben op train data\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 10B: SCALING OP TEST SET (MET TRAIN STATISTICS)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"STAP 10B: STANDARDISATIE OP TEST SET (MET TRAIN STATISTICS)\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "BELANGRIJK: We gebruiken GEEN fit() op test data!\n",
    "==================================================\n",
    "\n",
    "We gebruiken de TRAIN mean en std om test data te schalen.\n",
    "Dit betekent dat test data NIET per se mean=0 en std=1 zal hebben.\n",
    "\n",
    "Dit is CORRECT gedrag:\n",
    "- In productie hebben we ook nieuwe data die we schalen met train statistics\n",
    "- Test set moet \"ongezien\" blijven\n",
    "- Kleine afwijkingen van mean=0/std=1 in test zijn normaal en verwacht\n",
    "\"\"\")\n",
    "\n",
    "# Toon voorbeeld van niet-geschaalde data (TEST)\n",
    "print(\"\\nVoorbeeld TEST features VOOR scaling:\")\n",
    "display(X_test.head())\n",
    "\n",
    "print(\"\\nDescriptive statistics TEST VOOR scaling:\")\n",
    "display(X_test.describe())\n",
    "\n",
    "# TRANSFORM test data met TRAIN scaler (GEEN fit!)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Converteer terug naar DataFrame voor visualisatie\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"\\nVoorbeeld TEST features NA scaling:\")\n",
    "display(X_test_scaled.head())\n",
    "\n",
    "print(\"\\nDescriptive statistics TEST NA scaling:\")\n",
    "display(X_test_scaled.describe())\n",
    "\n",
    "print(\"\"\"\n",
    "INTERPRETATIE TEST:\n",
    "===================\n",
    "- Mean kan AFWIJKEN van 0 (bijvoorbeeld -0.15 of +0.20)\n",
    "- Std kan AFWIJKEN van 1 (bijvoorbeeld 0.95 of 1.08)\n",
    "- Dit is NORMAAL en CORRECT - test data is geschaald met TRAIN statistics\n",
    "- Kleine afwijkingen zijn verwacht als train en test distributie iets verschillen\n",
    "\"\"\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 10C: VERIFICATIE EN SAMENVATTING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"VERIFICATIE VAN SCALING\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Controleer of alle features geschaald zijn\n",
    "print(\"\\nControle: Zijn alle features geschaald?\")\n",
    "print(\"\\nTRAIN set - Mean en Std per feature (eerste 10):\")\n",
    "train_stats = pd.DataFrame({\n",
    "    'Mean': X_train_scaled.mean(),\n",
    "    'Std': X_train_scaled.std()\n",
    "}).head(10)\n",
    "display(train_stats)\n",
    "\n",
    "print(\"\\nTEST set - Mean en Std per feature (eerste 10):\")\n",
    "test_stats = pd.DataFrame({\n",
    "    'Mean': X_test_scaled.mean(),\n",
    "    'Std': X_test_scaled.std()\n",
    "}).head(10)\n",
    "display(test_stats)\n",
    "\n",
    "print(\"\\n‚úì TRAIN: Mean ‚âà 0, Std ‚âà 1 (exact, want scaler gefitted op train)\")\n",
    "print(\"‚ö†Ô∏è TEST: Mean en Std kunnen afwijken (normaal, want geschaald met train statistics)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STAP 10D: VISUALISATIE VAN SCALING EFFECT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"VISUALISATIE: VOOR vs NA SCALING\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Selecteer een paar features om te visualiseren\n",
    "features_to_plot = [col for col in ['Sleep Duration', 'Heart Rate', 'Daily Steps', 'BMI', 'Age'] \n",
    "                    if col in X_train.columns][:4]\n",
    "\n",
    "if len(features_to_plot) > 0:\n",
    "    fig, axes = plt.subplots(2, len(features_to_plot), figsize=(16, 8))\n",
    "    \n",
    "    for i, feature in enumerate(features_to_plot):\n",
    "        # Voor scaling (train)\n",
    "        axes[0, i].hist(X_train[feature], bins=20, edgecolor='black', alpha=0.7)\n",
    "        axes[0, i].set_title(f'{feature}\\nVOOR scaling (Train)')\n",
    "        axes[0, i].set_xlabel('Waarde')\n",
    "        axes[0, i].set_ylabel('Frequentie')\n",
    "        \n",
    "        # Na scaling (train)\n",
    "        axes[1, i].hist(X_train_scaled[feature], bins=20, edgecolor='black', alpha=0.7, color='green')\n",
    "        axes[1, i].set_title(f'{feature}\\nNA scaling (Train)')\n",
    "        axes[1, i].set_xlabel('Z-score')\n",
    "        axes[1, i].set_ylabel('Frequentie')\n",
    "        axes[1, i].axvline(0, color='red', linestyle='--', label='Mean=0')\n",
    "    \n",
    "    plt.suptitle('Effect van Standardisatie op Features (Training Set)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Geen numerieke features gevonden om te plotten\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì FEATURE SCALING VOLTOOID\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nSamenvatting:\")\n",
    "print(f\"  ‚Ä¢ Scaling methode: StandardScaler (Z-score normalisatie)\")\n",
    "print(f\"  ‚Ä¢ Scaler fitted op: TRAIN data ({X_train.shape[0]} samples)\")\n",
    "print(f\"  ‚Ä¢ Train features geschaald: {X_train_scaled.shape[1]} features\")\n",
    "print(f\"  ‚Ä¢ Test features geschaald: {X_test_scaled.shape[1]} features\")\n",
    "print(f\"  ‚Ä¢ Train mean ‚âà 0, std ‚âà 1: ‚úì\")\n",
    "print(f\"  ‚Ä¢ Test geschaald met TRAIN statistics: ‚úì\")\n",
    "print(f\"  ‚Ä¢ Data leakage voorkomen: ‚úì\")\n",
    "\n",
    "\n",
    "\n",
    "# Update variabelen voor volgende stappen\n",
    "X_train = X_train_scaled\n",
    "X_test = X_test_scaled\n",
    "\n",
    "print(\"\\n‚úì X_train en X_test zijn nu geschaald en klaar voor modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STAP 11: FEATURE SELECTION & ENGINEERING - OVERWEGINGEN\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAP 11: FEATURE SELECTION & ENGINEERING - OVERWEGINGEN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "HUIDIGE FEATURES:\n",
    "=================\n",
    "\n",
    "We hebben alle beschikbare features behouden na encoding:\n",
    "- Numerieke features: Sleep Duration, Quality of Sleep, Stress Level, etc.\n",
    "- One-hot encoded categorische features: Gender, BMI Category, Occupation\n",
    "\n",
    "\n",
    "WAAROM BEHOUDEN WE ALLE FEATURES?\n",
    "==================================\n",
    "\n",
    "Voor de BASELINE modellen gebruiken we bewust ALLE features, ook al hebben we\n",
    "in stap 7 (EDA) multicollineariteit gedetecteerd:\n",
    "\n",
    "- Systolic ‚Üî Diastolic: r = 0.979 (extreem hoog)\n",
    "- Physical Activity ‚Üî Daily Steps: r = 0.761 (hoog)\n",
    "- Sleep Duration ‚Üî Quality of Sleep: r = 0.847 (hoog)\n",
    "\n",
    "Rationale voor behouden:\n",
    "1. Data-driven benadering: Laat MODEL bepalen welke features belangrijk zijn\n",
    "2. Wetenschappelijke methode: Train eerst, analyseer dan\n",
    "3. Vergelijkingsbasis: Baseline (alle features) vs Optimized (geselecteerde features)\n",
    "4. Objectiviteit: Geen vooringenomen keuzes zonder bewijs\n",
    "\n",
    "FEATURE SELECTION STRATEGIE - IN ML FASE:\n",
    "==========================================\n",
    "\n",
    "In de \"Uitwerking ML Vraagstuk\" fase zullen we:\n",
    "\n",
    "STAP 1: BASELINE MODELS\n",
    "  ‚Üí Train Random Forest, XGBoost, Logistic Regression met ALLE 23 features\n",
    "  ‚Üí Evalueer performance en feature importance\n",
    "\n",
    "STAP 2: FEATURE IMPORTANCE ANALYSE\n",
    "  ‚Üí Analyseer feature importance uit tree-based modellen\n",
    "  ‚Üí Identificeer features met <1% importance\n",
    "  ‚Üí Analyseer correlaties in context van model performance\n",
    "  \n",
    "STAP 3: MULTICOLLINEARITEIT BEHANDELING\n",
    "  ‚ö†Ô∏è DIASTOLIC VERWIJDERING:\n",
    "     ‚Ä¢ Systolic vs Diastolic (r=0.979)\n",
    "     ‚Ä¢ Keuze: Behoud Systolic (klinisch belangrijker voor cardiovasculaire risico)\n",
    "     ‚Ä¢ Rationale: 95.8% overlap in informatie, geen toegevoegde voorspellende waarde\n",
    "  \n",
    "  üí° OVERIGE CORRELATIES:\n",
    "     ‚Ä¢ Physical Activity vs Daily Steps (r=0.761)\n",
    "       ‚Üí Beide behouden in baseline, evalueer feature importance\n",
    "     ‚Ä¢ Sleep Duration vs Quality (r=0.847)\n",
    "       ‚Üí Conceptueel verschillend (objectief vs subjectief), beide behouden\n",
    "\n",
    "STAP 4: OPTIMIZED MODELS\n",
    "  ‚Üí Retrain modellen met geselecteerde features\n",
    "  ‚Üí Vergelijk: Baseline (23 features) vs Optimized (‚âà20-22 features)\n",
    "  ‚Üí Evalueer: Accuracy, precision, recall, F1-score\n",
    "  ‚Üí Besluit: Behoud optimized model als performance gelijk of beter\n",
    "\n",
    "STAP 5: FEATURE ENGINEERING (OPTIONEEL)\n",
    "  Indien baseline performance onvoldoende:\n",
    "  ‚Ä¢ Sleep Efficiency = (Sleep Duration / 8) √ó Quality of Sleep\n",
    "  ‚Ä¢ Activity-Stress Balance = Physical Activity / (Stress Level + 1)\n",
    "  ‚Ä¢ BMI-Age Interaction = BMI √ó (Age / 50)\n",
    "  ‚Ä¢ High Risk Binary = (BMI > 30) & (Age > 50) & (Heart Rate > 80)\n",
    "\n",
    "SAMPLES/FEATURES RATIO ANALYSE:\n",
    "================================\n",
    "\n",
    "Huidige ratio: 80,000 samples / 23 features = 3,478:1\n",
    "\n",
    "‚úì UITSTEKEND! Vuistregels:\n",
    "  ‚Ä¢ Minimum ratio: 10:1 (wij hebben 3,478:1)\n",
    "  ‚Ä¢ Ideaal voor complex models: >100:1 (wij hebben dit!)\n",
    "  ‚Ä¢ Geen curse of dimensionality issues\n",
    "  ‚Ä¢ Voldoende data voor stabiele feature importance estimates\n",
    "\n",
    "ONZE AANPAK: \"START SIMPEL, ITEREER OP BASIS VAN DATA\"\n",
    "=======================================================\n",
    "\n",
    "1. Preprocessing: Behoud alle features (huidige fase)\n",
    "2. Baseline: Train met alle features\n",
    "3. Analyse: Feature importance + multicollineariteit impact\n",
    "4. Optimize: Verwijder redundante/onbelangrijke features\n",
    "5. Compare: Baseline vs Optimized performance\n",
    "6. Decide: Kies beste model op basis van metrics\n",
    "\n",
    "Dit is de INDUSTRIE STANDAARD aanpak en volgt wetenschappelijke methode.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"FINALE FEATURE SET VOOR BASELINE MODELING\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\nTRAINING SET:\")\n",
    "print(f\"  ‚Ä¢ Samples: {X_train.shape[0]:,}\")\n",
    "print(f\"  ‚Ä¢ Features: {X_train.shape[1]}\")\n",
    "print(f\"  ‚Ä¢ Samples/Features ratio: {X_train.shape[0] / X_train.shape[1]:,.1f}:1\")\n",
    "\n",
    "print(f\"\\nTEST SET:\")\n",
    "print(f\"  ‚Ä¢ Samples: {X_test.shape[0]:,}\")\n",
    "print(f\"  ‚Ä¢ Features: {X_test.shape[1]}\")\n",
    "\n",
    "print(f\"\\nFeature lijst ({X_train.shape[1]} features):\")\n",
    "\n",
    "# Groepeer features\n",
    "original_numeric = [col for col in X_train.columns if not any(\n",
    "    prefix in col for prefix in ['Gender_', 'Occupation_', 'BMI Category_']\n",
    ")]\n",
    "gender_features = [col for col in X_train.columns if col.startswith('Gender_')]\n",
    "occupation_features = [col for col in X_train.columns if col.startswith('Occupation_')]\n",
    "bmi_cat_features = [col for col in X_train.columns if col.startswith('BMI Category_')]\n",
    "\n",
    "print(\"\\n1. NUMERIEKE FEATURES:\")\n",
    "for i, feature in enumerate(original_numeric, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "if gender_features:\n",
    "    print(f\"\\n2. GENDER FEATURES ({len(gender_features)}):\")\n",
    "    for i, feature in enumerate(gender_features, 1):\n",
    "        print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "if occupation_features:\n",
    "    print(f\"\\n3. OCCUPATION FEATURES ({len(occupation_features)}):\")\n",
    "    for i, feature in enumerate(occupation_features, 1):\n",
    "        print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "if bmi_cat_features:\n",
    "    print(f\"\\n4. BMI CATEGORY FEATURES ({len(bmi_cat_features)}):\")\n",
    "    for i, feature in enumerate(bmi_cat_features, 1):\n",
    "        print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"DATA QUALITY FINAL CHECK\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\n‚úì Missing values: {X_train.isnull().sum().sum()} (train) + {X_test.isnull().sum().sum()} (test)\")\n",
    "print(f\"‚úì Infinite values: {np.isinf(X_train.values).sum()} (train) + {np.isinf(X_test.values).sum()} (test)\")\n",
    "print(f\"‚úì Data types: All numeric ({X_train.select_dtypes(include=[np.number]).shape[1]}/{X_train.shape[1]} features)\")\n",
    "print(f\"‚úì Scaling: Completed (StandardScaler, fit on train)\")\n",
    "print(f\"‚úì Encoding: Completed (One-hot + Label encoding)\")\n",
    "print(f\"‚úì Outliers: Treated (conservative capping)\")\n",
    "print(f\"‚úì Data leakage: Prevented (fit train ‚Üí transform test)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì DATA PREPROCESSING PIPELINE VOLTOOID\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "üöÄ DATA IS KLAAR VOOR MODEL TRAINING!\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
